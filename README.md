# MTER
&nbsp;
<p align="center">
    <img src="mter_logo.png#gh-light-mode-only" width="60%"/>
    <img src="assets/towhee_logo_dark.png#gh-dark-mode-only" width="60%"/>
</p>


<h3 align="center">
  <p style="text-align: center;"> <span style="font-weight: bold; font: Arial, sans-serif;"></span>METR:Multi-task Emotion Recognition Based on Context-aware Attention Module</p>
</h3>

<h3 align="center">
  <p style="text-align: center;">
  <a href="README.md" target="_blank">ENGLISH</a> | <a href="README_CN.md">中文文档</a>
  </p>
</h3>

<div class="column" align="middle">
  <a href="https://zhanglina94.github.io">
    <img src="https://img.shields.io/badge/join-slack-orange?style=flat" alt="join-slack"/>
  </a>
  <a href=" ">
    <img src=" " alt="E@"/>
  </a>
  <a href="https://www.apache.org/licenses/LICENSE-2.0">
    <img src="https://img.shields.io/badge/license-apache2.0-green?style=flat" alt="license"/>
  </a>
  <a href=" ">
    <img src=" " alt="github actions"/>
  </a>

</div>

&nbsp;

[mter](https://github.com/zhanglina94/MTER/edit/main/README.md) 
...

:art:&emsp;**Dataset:** EMOTIC,EMOTIC_face;

:mortar_board:&emsp;**Model:** Resnet18,mobilenetV2;

:package:&emsp;**Data Processing:** ...

:snake:&emsp;**API:** ...

## What's New

**2022.06.13**

* Added  model: [**nnfp**]()
* Added two image embedding models: [**RepMLP**](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/repmlp), [**WaveViT**](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/wave_vit)



## Getting started

MTER requires Python 3.6+. You can install  via `pip`:


If you run into any pip-related install problems, please try to upgrade pip with `pip install -U pip`.

Let's try your first Towhee pipeline. Below is an example for how to create a CLIP-based cross modal retrieval pipeline with only 15 lines of code.


<img src="   " style="width: 60%; height: 60%">

Learn more examples from the [UN](  ).

## Core Concepts

- -

- __A__:

- __B__: 

- __C__:

- __D__: 

## Lenci
